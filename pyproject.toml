[tool.poetry]
name = "Autoembedder"
version = "1.0"
description = "PyTorch autoencoder with additional embeddings layer for categorical data."
authors = ["Chris Lemke <chris.lemke@me.com>"]
repository = "https://github.com/chrislemke/autoembedder"
packages = [{ include = "autoembedder" }]

[tool.poetry.dependencies]
python = "3.10.12"
dask = "2022.04.0"
pyarrow = "7.0.0"
pandas = "1.4.2"
torch = "1.11.0"
torchvision = "0.12."
torchinfo = "1.6.5"
einops = "0.4.1"
tqdm = "4.64.0"
tensorboard = "2.8.0"
pytorch-ignite = "0.4.8"
numpy = "1.22.3"


[tool.poetry.dev-dependencies]
black = {extras = ["jupyter"], version = "22.3.0"}
pylint = "2.13.5"
isort = "5.10.1"
mypy = "0.942"

[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"

[tool.isort]
profile = "black"

[tool.pylint.'MESSAGES CONTROL']
max-line-length = 88
disable = [
    "C0412",
    "R0903",
    "R0913",
    "C0116",
    "C0114",
    "C0103",
    "C0115",
    "E1136",
    "C0413",
    "W1203",
    "W0511",
    "E1101",
    "E0011",
    "R0902",
    "W0707",
    "C0415",
    "W1514",
    "W0404",
    "W0621",
    "R0801",
    "R1710",
    "R0914",
    "E1102",
    "C0201",
    "C0411",
    "C0330",
    "C0326",
    "E0611",
    "E0401",
    "E0401",
    "C0301",
    "C0303"
    ]